{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ed5df6",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ae9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "from zipfile import ZipFile\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1a9b6c",
   "metadata": {},
   "source": [
    "**Creating Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6cd3a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(save_location,url,file_name):\n",
    "  \n",
    "  '''Download any file with file name and url provided'''\n",
    "  \n",
    "\n",
    "  local_filename = save_location + file_name\n",
    "  local_filename = '/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye'+ file_name\n",
    "  \n",
    "  \n",
    "  # NOTE the stream=True parameter below\n",
    "  with requests.get(url, stream=True) as r:\n",
    "    r.raise_for_status()\n",
    "    with open(local_filename, 'wb') as f:\n",
    "         for chunk in r.iter_content(chunk_size=1024): \n",
    "            f.write(chunk)\n",
    "  return (local_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a1e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zip_url(xml_file_path):\n",
    "  \n",
    "  '''Extract zip file from xml file'''\n",
    "  \n",
    "  \n",
    "  empty_list=[]\n",
    "  \n",
    "  f = open(xml_file_path, 'r')\n",
    "  \n",
    "  xml_file = f.read()\n",
    "  \n",
    "  soup = BeautifulSoup(xml_file, 'lxml')\n",
    "  \n",
    "  \n",
    "  for tag in soup.findAll(\"str\"):\n",
    "    #print(tag)\n",
    "    \n",
    "    if tag[\"name\"] == 'download_link':\n",
    "      empty_list.append(tag.text)\n",
    "  return empty_list\n",
    "  \n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "581b6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(xml_file, csv_path):\n",
    "    \"\"\" Creates CSV from XML File \"\"\"\n",
    "    try:\n",
    "        # Checking if the path exists or not\n",
    "        if not os.path.exists(csv_path):\n",
    "            # Creating the path\n",
    "            logging.warning(\"Creating CSV file path\")\n",
    "            os.makedirs(csv_path)\n",
    "\n",
    "        # Extracting the csv file name from xml file\n",
    "        csv_fname = xml_file.split(os.sep)[-1].split(\".\")[0] + \".csv\"\n",
    "\n",
    "        # Creating csv file path\n",
    "        csv_file = os.path.join(csv_path, csv_fname)\n",
    "\n",
    "        logging.warning(\"Loading the xml file\")\n",
    "        # Creating xml file itertor\n",
    "        xml_iter = ET.iterparse(xml_file, events=(\"start\",))\n",
    "\n",
    "        csv_columns = [\n",
    "            \"FinInstrmGnlAttrbts.Id\",\n",
    "            \"FinInstrmGnlAttrbts.FullNm\",\n",
    "            \"FinInstrmGnlAttrbts.ClssfctnTp\",\n",
    "            \"FinInstrmGnlAttrbts.CmmdtyDerivInd\",\n",
    "            \"FinInstrmGnlAttrbts.NtnlCcy\",\n",
    "            \"Issr\",\n",
    "        ]\n",
    "\n",
    "        # Creating empty dataframe with the required column names\n",
    "        df = pd.DataFrame(columns=csv_columns)\n",
    "\n",
    "        # List to store the extacted data\n",
    "        extracted_data = []\n",
    "\n",
    "        logging.warning(\"Parsing the xml file...\")\n",
    "        logging.warning(\"Extracting the required data from xml\")\n",
    "        # Traversing the xml data\n",
    "        for event, element in xml_iter:\n",
    "\n",
    "            # Checking for start of the tags\n",
    "            if event == \"start\":\n",
    "\n",
    "                # Checking for TermntdRcrd tag in which the required data is\n",
    "                if \"TermntdRcrd\" in element.tag:\n",
    "\n",
    "                    # Dictionary to store require data in single element\n",
    "                    data = {}\n",
    "\n",
    "                    # List of the required tags (FinInstrmGnlAttrbts, Issr)\n",
    "                    reqd_elements = [\n",
    "                        (elem.tag, elem)\n",
    "                        for elem in element\n",
    "                        if \"FinInstrmGnlAttrbts\" in elem.tag or \"Issr\" in elem.tag\n",
    "                    ]\n",
    "\n",
    "                    # Traversing through the required tags\n",
    "                    for tag, elem in reqd_elements:\n",
    "\n",
    "                        if \"FinInstrmGnlAttrbts\" in tag:\n",
    "\n",
    "                            # Traversing through the child elements of\n",
    "                            # FinInstrmGnlAttrbts element\n",
    "                            for child in elem:\n",
    "\n",
    "                                # Adding the extrcated data in the dictionary\n",
    "                                if \"Id\" in child.tag:\n",
    "                                    data[csv_columns[0]] = child.text\n",
    "                                elif \"FullNm\" in child.tag:\n",
    "                                    data[csv_columns[1]] = child.text\n",
    "                                elif \"ClssfctnTp\" in child.tag:\n",
    "                                    data[csv_columns[2]] = child.text\n",
    "                                elif \"CmmdtyDerivInd\" in child.tag:\n",
    "                                    data[csv_columns[3]] = child.text\n",
    "                                elif \"NtnlCcy\" in child.tag:\n",
    "                                    data[csv_columns[4]] = child.text\n",
    "\n",
    "                        # Extracting Issr Tag value\n",
    "                        else:\n",
    "                            data[csv_columns[5]] = child.text\n",
    "\n",
    "                    # Appending the single element extracted data in the list\n",
    "                    extracted_data.append(data)\n",
    "\n",
    "        logging.warning(\"All the required data extracted from xml file\")\n",
    "\n",
    "        # Appending the extracted data in the data frame\n",
    "        df = df.append(extracted_data, ignore_index=True)\n",
    "\n",
    "        logging.warning(\"Dropping empty rows\")\n",
    "        # Removes empty rows from the dataframe\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        logging.warning(\"Creating the CSV file\")\n",
    "        # Creates csv file from the dataframe\n",
    "        df.to_csv(csv_file, index=False)\n",
    "\n",
    "        # returning the csv file path\n",
    "        return csv_file\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while extracting - {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47393a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(url_zip,save_location):\n",
    "  '''function to extract zip file to a directory'''\n",
    "\n",
    "\n",
    "  # specifying the zip file name\n",
    "  file_name = url_zip\n",
    "  loc = '/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye'\n",
    "  \n",
    "  # opening the zip file in READ mode\n",
    "  with ZipFile(file_name, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    "    \n",
    "    # extracting all the files\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extractall(path=loc)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b433db2",
   "metadata": {},
   "source": [
    "## Implementing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0954af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_path='https://registers.esma.europa.eu/solr/esma_registers_firds_files/select?q=*&fq=publication_date:%5B2021-01-17T00:00:00Z+TO+2021-01-19T23:59:59Z%5D&wt=xml&indent=true&start=0&rows=100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1a52f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = '/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf96043",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_loc = save_location + 'xml_file.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43589ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleyexml_file.xml'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_file(save_location,url_path,'xml_file.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4942214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\anaconda3\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "zip_url_list = get_zip_url(xml_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fb18580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://firds.esma.europa.eu/firds/DLTINS_20210117_01of01.zip',\n",
       " 'http://firds.esma.europa.eu/firds/DLTINS_20210119_01of02.zip',\n",
       " 'http://firds.esma.europa.eu/firds/DLTINS_20210119_02of02.zip',\n",
       " 'http://firds.esma.europa.eu/firds/DLTINS_20210118_01of01.zip']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55ba851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(zip_url_list)):\n",
    "  download_file(save_location,zip_url_list[i],'zipfile'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caa5cbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                                             Modified             Size\n",
      "DLTINS_20210117_01of01.xml                     2021-01-17 01:17:12    143278061\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "File Name                                             Modified             Size\n",
      "DLTINS_20210119_01of02.xml                     2021-01-19 03:21:08    521464972\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "File Name                                             Modified             Size\n",
      "DLTINS_20210119_02of02.xml                     2021-01-19 03:21:56    363082618\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "File Name                                             Modified             Size\n",
      "DLTINS_20210118_01of01.xml                     2021-01-18 01:21:22      1439631\n",
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loc = '/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye'\n",
    "for i in range(4):\n",
    "  extract_zip(loc +'zipfile'+str(i),save_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2df8fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_extracted_xml consist list of xml files extracted from zip\n",
    "\n",
    "\n",
    "input_extracted_xml=[\"/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye/DLTINS_20210117_01of01.xml\",\n",
    "                     \"/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye/DLTINS_20210118_01of01.xml\",\n",
    "                     \"/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye/DLTINS_20210119_01of02.xml\",\n",
    "                     \"/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye/DLTINS_20210119_02of02.xml\"]\n",
    "\n",
    "\n",
    "#output_path_converted_csv is path where converted csv wil be saved\n",
    "\n",
    "\n",
    "\n",
    "output_path_converted_csv=\"/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d110c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6f0358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading the xml file\n",
      "WARNING:root:Parsing the xml file...\n",
      "WARNING:root:Extracting the required data from xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye/DLTINS_20210117_01of01.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:All the required data extracted from xml file\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_5412\\3209183778.py:87: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(extracted_data, ignore_index=True)\n",
      "WARNING:root:Dropping empty rows\n",
      "WARNING:root:Creating the CSV file\n",
      "WARNING:root:Loading the xml file\n",
      "WARNING:root:Parsing the xml file...\n",
      "WARNING:root:Extracting the required data from xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye/DLTINS_20210118_01of01.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:All the required data extracted from xml file\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_5412\\3209183778.py:87: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(extracted_data, ignore_index=True)\n",
      "WARNING:root:Dropping empty rows\n",
      "WARNING:root:Creating the CSV file\n",
      "WARNING:root:Loading the xml file\n",
      "WARNING:root:Parsing the xml file...\n",
      "WARNING:root:Extracting the required data from xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye/DLTINS_20210119_01of02.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:All the required data extracted from xml file\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_5412\\3209183778.py:87: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(extracted_data, ignore_index=True)\n",
      "WARNING:root:Dropping empty rows\n",
      "WARNING:root:Creating the CSV file\n",
      "WARNING:root:Loading the xml file\n",
      "WARNING:root:Parsing the xml file...\n",
      "WARNING:root:Extracting the required data from xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rahul/OneDrive/Desktop/jupyter Projects/Steeleye/steeleye/DLTINS_20210119_02of02.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:All the required data extracted from xml file\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_5412\\3209183778.py:87: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(extracted_data, ignore_index=True)\n",
      "WARNING:root:Dropping empty rows\n",
      "WARNING:root:Creating the CSV file\n"
     ]
    }
   ],
   "source": [
    "# for loop to covert all xml files extracted from zip\n",
    "\n",
    "for link in input_extracted_xml:\n",
    "  print(link)\n",
    "\n",
    "  #calling create_csv function to convert xml to csv\n",
    "  \n",
    "  create_csv(link, output_path_converted_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3879a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/rahul/OneDrive/Desktop/Jupyter Projects/Steeleye/steeleye/DLTINS_20210117_01of01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76f1b6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100086 entries, 0 to 100085\n",
      "Data columns (total 6 columns):\n",
      " #   Column                              Non-Null Count   Dtype \n",
      "---  ------                              --------------   ----- \n",
      " 0   FinInstrmGnlAttrbts.Id              100086 non-null  object\n",
      " 1   FinInstrmGnlAttrbts.FullNm          100086 non-null  object\n",
      " 2   FinInstrmGnlAttrbts.ClssfctnTp      100086 non-null  object\n",
      " 3   FinInstrmGnlAttrbts.CmmdtyDerivInd  100086 non-null  bool  \n",
      " 4   FinInstrmGnlAttrbts.NtnlCcy         100086 non-null  object\n",
      " 5   Issr                                100086 non-null  bool  \n",
      "dtypes: bool(2), object(4)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1634c018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FinInstrmGnlAttrbts.Id</th>\n",
       "      <th>FinInstrmGnlAttrbts.FullNm</th>\n",
       "      <th>FinInstrmGnlAttrbts.ClssfctnTp</th>\n",
       "      <th>FinInstrmGnlAttrbts.CmmdtyDerivInd</th>\n",
       "      <th>FinInstrmGnlAttrbts.NtnlCcy</th>\n",
       "      <th>Issr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE000A1R07V3</td>\n",
       "      <td>Kreditanst.f.Wiederaufbau     Anl.v.2014 (2021)</td>\n",
       "      <td>DBFTFB</td>\n",
       "      <td>False</td>\n",
       "      <td>EUR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE000A1R07V3</td>\n",
       "      <td>KFW 1 5/8 01/15/21</td>\n",
       "      <td>DBFTFB</td>\n",
       "      <td>False</td>\n",
       "      <td>EUR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE000A1R07V3</td>\n",
       "      <td>Kreditanst.f.Wiederaufbau Anl.v.2014 (2021)</td>\n",
       "      <td>DBFTFB</td>\n",
       "      <td>False</td>\n",
       "      <td>EUR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE000A1R07V3</td>\n",
       "      <td>Kreditanst.f.Wiederaufbau Anl.v.2014 (2021)</td>\n",
       "      <td>DBFTFB</td>\n",
       "      <td>False</td>\n",
       "      <td>EUR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE000A1X3J56</td>\n",
       "      <td>IKB Deutsche Industriebank AG Stufenz.MTN-IHS ...</td>\n",
       "      <td>DTVUFB</td>\n",
       "      <td>False</td>\n",
       "      <td>EUR</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FinInstrmGnlAttrbts.Id                         FinInstrmGnlAttrbts.FullNm  \\\n",
       "0           DE000A1R07V3    Kreditanst.f.Wiederaufbau     Anl.v.2014 (2021)   \n",
       "1           DE000A1R07V3                                 KFW 1 5/8 01/15/21   \n",
       "2           DE000A1R07V3        Kreditanst.f.Wiederaufbau Anl.v.2014 (2021)   \n",
       "3           DE000A1R07V3        Kreditanst.f.Wiederaufbau Anl.v.2014 (2021)   \n",
       "4           DE000A1X3J56  IKB Deutsche Industriebank AG Stufenz.MTN-IHS ...   \n",
       "\n",
       "  FinInstrmGnlAttrbts.ClssfctnTp  FinInstrmGnlAttrbts.CmmdtyDerivInd  \\\n",
       "0                         DBFTFB                               False   \n",
       "1                         DBFTFB                               False   \n",
       "2                         DBFTFB                               False   \n",
       "3                         DBFTFB                               False   \n",
       "4                         DTVUFB                               False   \n",
       "\n",
       "  FinInstrmGnlAttrbts.NtnlCcy   Issr  \n",
       "0                         EUR  False  \n",
       "1                         EUR  False  \n",
       "2                         EUR  False  \n",
       "3                         EUR  False  \n",
       "4                         EUR  False  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd286685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe is saved as CSV in S3 bucket.\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO \n",
    "\n",
    "import boto3\n",
    "\n",
    "\n",
    "#Creating Session With Boto3.\n",
    "session = boto3.Session(\n",
    "aws_access_key_id='XXXXXX',\n",
    "aws_secret_access_key='XXXXXX'\n",
    ")\n",
    "\n",
    "#Creating S3 Resource From the Session.\n",
    "s3_res = session.resource('s3')\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "\n",
    "df.to_csv(csv_buffer)\n",
    "\n",
    "bucket_name = 'assignmentsteeleye'\n",
    "\n",
    "s3_object_name = 'DLTINS_20210117_01of01.csv'\n",
    "\n",
    "s3_res.Object(bucket_name, s3_object_name).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "print(\"Dataframe is saved as CSV in S3 bucket.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd43cbb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
